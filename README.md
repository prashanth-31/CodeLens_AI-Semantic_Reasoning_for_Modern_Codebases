# CodeLens AI â€” Semantic Code Impact Analyzer

<div align="center">

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Ollama](https://img.shields.io/badge/powered%20by-Ollama-orange.svg)
![Streamlit](https://img.shields.io/badge/UI-Streamlit-red.svg)

**A production-ready tool that detects downstream semantic risks when you change code**

Uses call-graph analysis + local LLM reasoning via Ollama to prevent breaking changes before they reach production.

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Quick Start](#-quick-start) â€¢ [Documentation](#-documentation) â€¢ [Contributing](#-contributing)

</div>

---

## ğŸ¯ The Problem This Solves

When developers modify code, they often break things in distant parts of the codebase â€” not through compile errors, but through **semantic drift**:

```python
# Developer changes this:
def get_user_data(user_id):
    return {"id": user_id, "name": "John"}  # Returns dict

# 50 files later, someone expects this format:
user = get_user_data(123)
print(user.name)  # Now breaks! Was expecting object, got dict
```

**The Gap:**
- âœ… Linters catch syntax/type issues
- âœ… Tests catch what they cover
- âŒ **No tool traces semantic impact across your codebase**

**CodeLens AI bridges this gap** by combining:
1. **Static call-graph analysis** â€” traces all downstream dependencies
2. **LLM semantic reasoning** â€” analyzes: "What assumptions might break?"
3. **Risk scoring** â€” prioritizes critical changes for review

---

## âœ¨ Features

### ğŸ”¬ Semantic Impact Analysis (Core Feature)
- **Call Graph Builder** â€” AST-based analysis of your entire codebase
- **Downstream Tracing** â€” Identifies all functions affected by your changes
- **LLM-Powered Analysis** â€” Uses deepseek-coder via Ollama to detect semantic risks
- **Risk Scoring** â€” Categorizes changes as Low/Medium/High/Critical
- **Multi-Format Reports** â€” Output as Markdown, JSON, or console
- **Git Integration** â€” Analyze commits, branches, or specific file changes
- **100% Local** â€” No API keys, no data leaves your machine

### ğŸ“ Intelligent Documentation
- **Auto-Generated Docstrings** â€” Context-aware function documentation
- **Module Overviews** â€” High-level Markdown summaries
- **Commit Summarization** â€” LLM-powered git commit explanations
- **Export Options** â€” Python stubs, Markdown, or inject directly

### ğŸ“Š Code Visualization
- **UML Class Diagrams** â€” Auto-generated architecture diagrams
- **Dependency Graphs** â€” Visualize relationships and inheritance
- **DOT & PNG Export** â€” Using Graphviz for professional output

### ğŸ’¬ Intelligent Codebase Q&A
- **Semantic Search** â€” TF-IDF + LLM retrieval for accurate answers
- **Context-Aware** â€” References specific files, functions, and line numbers
- **Conversation History** â€” Multi-turn conversations about your code
- **Source Citations** â€” Always shows where information comes from

### ğŸ¨ Modern Streamlit UI
- **Four Integrated Tabs** â€” Docstrings, UML, Chat, Impact Analysis
- **Dark/Light Theme** â€” Professional, responsive design
- **Real-Time Progress** â€” Live status updates during processing
- **Export Ready** â€” Download results in multiple formats

---

## ğŸ“‹ Requirements

| Component | Version | Purpose |
|-----------|---------|---------|
| Python | 3.8+ | Core runtime |
| Ollama | Latest | LLM inference (deepseek-coder) |
| Graphviz | Latest (optional) | UML diagram rendering |
| Git | Any (optional) | Impact analysis on commits |

**Python Dependencies** (auto-installed):
```
streamlit>=1.28.0
GitPython>=3.1.40
click
requests
torch
transformers
scikit-learn
pydot
graphviz
python-dotenv
astor
```

---

## ğŸš€ Installation

### 1ï¸âƒ£ Install Ollama

**Windows:**
```powershell
# Download from https://ollama.com/download
# Or use winget:
winget install Ollama.Ollama
```

**macOS/Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### 2ï¸âƒ£ Pull the AI Model

```bash
ollama pull deepseek-coder:6.7b
```

### 3ï¸âƒ£ Clone & Setup Project

```bash
git clone https://github.com/prashanth-31/CodeLens_AI-Semantic_Reasoning_for_Modern_Codebases.git
cd CodeLens_AI-Semantic_Reasoning_for_Modern_Codebases

# Create virtual environment
python -m venv .venv

# Activate (Windows)
.\.venv\Scripts\Activate.ps1

# Activate (macOS/Linux)
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 4ï¸âƒ£ (Optional) Install Graphviz

**Windows:**
```powershell
winget install graphviz
# Add to PATH: C:\Program Files\Graphviz\bin
```

**macOS:**
```bash
brew install graphviz
```

**Linux:**
```bash
sudo apt-get install graphviz  # Debian/Ubuntu
sudo yum install graphviz      # RHEL/CentOS
```

### 5ï¸âƒ£ Verify Installation

```bash
# Start Ollama (if not running)
ollama serve

# Test the CLI
python -m ai_doc_layer --help

# Or launch the Streamlit UI
streamlit run app.py
```

---

## ğŸ¯ Quick Start

### ğŸ–¥ï¸ Streamlit UI (Recommended)

```bash
# Start Ollama first
ollama serve

# Launch the app
streamlit run app.py

# Navigate to http://localhost:8501
```

**Features:**
- ğŸ“ **Tab 1: Docstring Generator** â€” Generate docs for entire projects
- ğŸ“Š **Tab 2: UML Visualizer** â€” Create class diagrams
- ğŸ’¬ **Tab 3: Code Chat** â€” Ask questions about your codebase
- ğŸ”¬ **Tab 4: Impact Analysis** â€” Analyze commit changes

### ğŸ”§ CLI Usage

#### Semantic Impact Analysis

**Analyze last commit:**
```bash
python -m ai_doc_layer analyze-impact ./my-project
```

**Compare specific commits:**
```bash
python -m ai_doc_layer analyze-impact ./my-project \
  --base HEAD~3 \
  --target HEAD \
  --output markdown \
  --out-file impact-report.md
```

**Analyze specific file changes:**
```bash
python -m ai_doc_layer analyze-file-impact ./my-project ./src/api.py
```

#### Documentation Generation

**Generate docstrings for entire project:**
```bash
python -m ai_doc_layer generate ./my-project
```

**Only changed files:**
```bash
python -m ai_doc_layer generate ./my-project --only-changed
```

**Generate UML diagrams:**
```bash
python -m ai_doc_layer generate-uml ./my-project --out-dir ./docs/diagrams
```

#### Codebase Q&A

```bash
python -m ai_doc_layer ask ./my-project "How does the authentication system work?"
```

---

## ğŸ“Š Example Output

### Impact Analysis Report

```
============================================================
SEMANTIC IMPACT ANALYSIS REPORT
============================================================
Repository: my-awesome-project
Commits: abc123..def456
Analysis Time: 2024-12-07 15:30:42

ğŸ“Š SUMMARY
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Files Changed:           5
Functions Modified:      8
Downstream Affected:     24
High/Critical Risk:      2 âš ï¸
Medium Risk:             3 âš¡
Low Risk:                3 âœ“

ğŸ”´ CRITICAL RISKS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“„ src/auth/validator.py::validate_token (line 45)
   Downstream Impact: 12 functions
   
   RISK ANALYSIS:
   â€¢ Changed return type from bool to dict
   â€¢ 8 callers expect boolean response
   â€¢ Breaking change in error handling flow
   â€¢ Affects: login_handler, refresh_token, check_permissions
   
   RECOMMENDED ACTIONS:
   1. Update all callers to handle dict response
   2. Add backward compatibility layer
   3. Write tests for: login_handler, api_middleware
   
ğŸŸ¡ MEDIUM RISKS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[Additional details...]

ğŸ“¥ FULL REPORT: impact-report.md
```

---

## ğŸ—ï¸ Architecture

```
CodeLens_AI/
â”œâ”€â”€ app.py                      # Streamlit web interface
â”œâ”€â”€ ai_doc_layer/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                 # Click-based CLI commands
â”‚   â”œâ”€â”€ ollama_client.py       # Ollama LLM integration
â”‚   â”œâ”€â”€ call_graph.py          # AST-based call graph builder
â”‚   â”œâ”€â”€ impact_analyzer.py     # Semantic impact analysis engine
â”‚   â”œâ”€â”€ code_parser.py         # Python AST parsing utilities
â”‚   â”œâ”€â”€ doc_generator.py       # Docstring generation
â”‚   â”œâ”€â”€ search_index.py        # TF-IDF semantic search
â”‚   â”œâ”€â”€ visualizer.py          # UML generation
â”‚   â”œâ”€â”€ validation.py          # Input validation utilities
â”‚   â”œâ”€â”€ cache.py               # Response caching
â”‚   â””â”€â”€ config.py              # Configuration management
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ pyproject.toml            # Package configuration
â”œâ”€â”€ setup.cfg                 # Build configuration
â””â”€â”€ README.md                 # This file
```

---

## âš™ï¸ Configuration

### Environment Variables

```bash
# Ollama server URL (default: http://localhost:11434)
export OLLAMA_HOST="http://your-host:11434"

# Custom model (default: deepseek-coder:6.7b)
export OLLAMA_MODEL="codellama:13b"

# Timeout for LLM requests (default: 300 seconds)
export OLLAMA_TIMEOUT="600"
```

### Programmatic Configuration

```python
from ai_doc_layer.ollama_client import OllamaClient

# Custom configuration
client = OllamaClient(
    base_url="http://localhost:11434",
    model="deepseek-coder:6.7b",
    timeout=600  # 10 minutes for large analyses
)
```

---

## ğŸ§ª Development & Testing

### Run Tests

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run tests
pytest tests/

# With coverage
pytest --cov=ai_doc_layer tests/
```

### Code Quality

```bash
# Format code
black ai_doc_layer/

# Lint
flake8 ai_doc_layer/

# Type checking
mypy ai_doc_layer/
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸŒŸ Why CodeLens AI?

| Tool | Call Graph | Semantic Analysis | Local | Risk Scoring |
|------|------------|-------------------|-------|--------------|
| **CodeLens AI** | âœ… | âœ… | âœ… | âœ… |
| Linters (flake8, pylint) | âŒ | âŒ | âœ… | âŒ |
| Type Checkers (mypy) | âŒ | âŒ | âœ… | âŒ |
| Unit Tests | âŒ | Partial | âœ… | âŒ |
| CodeRabbit / GitHub Copilot | âŒ | Superficial | âŒ | âŒ |
| SonarQube | Partial | âŒ | âŒ | Limited |

**CodeLens AI is the only tool that combines call-graph tracing with LLM semantic reasoning, running 100% locally.**

---

## ğŸ“ Support

- ğŸ› **Issues**: [GitHub Issues](https://github.com/prashanth-31/CodeLens_AI-Semantic_Reasoning_for_Modern_Codebases/issues)
- ğŸ“§ **Contact**: [Create an issue](https://github.com/prashanth-31/CodeLens_AI-Semantic_Reasoning_for_Modern_Codebases/issues/new)
- ğŸ“– **Documentation**: See [FIXES_APPLIED.md](FIXES_APPLIED.md) for recent improvements

---

## ğŸ™ Acknowledgments

- **Ollama** â€” For making local LLM inference accessible
- **DeepSeek** â€” For the excellent deepseek-coder model
- **Streamlit** â€” For the amazing UI framework
- **Python Community** â€” For the robust ecosystem

---

<div align="center">

**â­ Star this repo if you find it useful! â­**

Made with â¤ï¸ by the CodeLens AI team

</div>